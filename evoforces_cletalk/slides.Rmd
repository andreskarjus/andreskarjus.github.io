---
title: "Challenges in<br>detecting evolutionary forces<br>in language change <br>using diachronic corpora"

author: "Andres Karjus<br><font size=5>(supervised by Kenny Smith, Simon Kirby, Richard A. Blythe)<br>Centre for Language Evolution, University of Edinburgh</font>"
date: "CLE seminar, 6.11.2018"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: false
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
---
class:inverse

<style>
.remark-slide-content {
  padding-top: 7px;
  padding-left: 25px;
  padding-right: 20px;
  padding-bottom: 30px;
}
body { 
  line-height: 3em;
} 
.mjx-chtml{ font-size: 100% !important; } 
.small { font-size: 50%; margin-top:0em; margin-bottom:0em}

p {margin-bottom:0em}

</style>


```{r setup, echo=F}
options(htmltools.dir.version = FALSE)
options(servr.daemon = TRUE)
knitr::opts_chunk$set(echo = FALSE, message=F,warning=F,dev="png",dpi=100)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
mono_light(
  base_color = rgb(0,0,0.2),
  black_color = "black",
  background_color = "white",
  header_font_google = google_font("Nanum Gothic"),
  text_font_google   = google_font("Nanum Gothic", "300", "300i"),
  text_slide_number_font_size = "0.4em",
  header_h1_font_size = "50px",
  text_font_size = "35px",
  text_font_family_fallback = "Helvetica",
  code_font_google   = google_font("Droid Mono"),
  title_slide_background_image = "cle.png",
  title_slide_background_size = "8%",
  title_slide_background_position = "top right",
  link_color = "lightblue"
)
```

```{r functions}
#knitr::knit_exit() # titleslide debug handbrake

library(RColorBrewer)
library(dplyr)
library(plotly)
load("/Users/pplsuser/Dropbox/phd/selection_replypaper/cletalk/binresults.RData")
library(plotly)
load("/Users/pplsuser/Dropbox/phd/selection_replypaper/cletalk/plotlys.RData")
load(file="~/Desktop/korpused/wright-fisher_simulations4.RData")
source("/Users/pplsuser/Dropbox/phd/selection_replypaper/fitmap_plotters.R")


wfsim = function(s,         # selection coefficient (e.g., 0, 0.1)
                 N=1000,    # population size
                 start=500, # start mutant pop value (e.g. 500 out of 1000 if 0.5 case)
                 len=200    # n generations to simulate (time series length)
){ 
  # based on some course materials: https://public.wsu.edu/~gomulki/mathgen/materials/wrightfisher.R
  j=c(start, rep(NA, len-1))   # initialize series with starting value
  for(i in 2:len)	{  # simulate W-F model
    p.star = j[i-1]*(1+s)/(j[i-1]*s + N)          # post-selection expected frequency
    j[i]=rbinom(n=1, size=N, prob=min(p.star,1))  # generates random deviates from the binomial distr (yields new number of mutants)
    # n=1 just one  value, size=number of trials (=popsize), prob=probability of success on each trial
    # (floating point errors, need to take care with min() so prob is <=1)
  }
  return(j) # returns the series
}
FIT = function(af.vec, tp.vec=NULL, returntest=F, plotit=F){
  require(dplyr)
  if(is.null(tp.vec)){
    tp.vec = (1:length(af.vec))[!is.na(af.vec)] # gaps affect the p-value!
  }
  if(any(is.na(af.vec))){  # remove NAs
    af.vec = af.vec[!is.na(af.vec)]
  }
  
  if(length(af.vec) == 0) { stop("all NA")}
  if(sum(af.vec >= 1 | af.vec <= 0)){ 
    warning(paste("min, max values are", min(af.vec), max(af.vec), ", must be in (0,1), force-fixing" ))
    af.vec=ifelse(af.vec <= 0, 0.001, ifelse(af.vec >= 1, 0.999, af.vec))
  }
  if(length(af.vec)!= length(tp.vec)){
    stop("tp.vec and af.vec must be the same length")
  }
  
  Yi <- (lead(af.vec) - af.vec)/sqrt(2*af.vec*(1 - af.vec)*(lead(tp.vec) - tp.vec))
  #Remove the NA caused by the lead function
  Yi <- Yi[!is.na(Yi)]
  
  # for (i in c(2:q)) { # R indexes from 1 rather than 0
  #   Y[i-1] = (v[i] - v[i - 1])/sqrt( 2*v[i-1]*(1 - v[i-1])*(t[i] - t[i-1]) )
  # }
  
  #You should only apply FIT to values away from the boundaries. 
  if(sum(Yi == Inf) > 0 | sum(is.nan(Yi) > 0)){
    stop("remove problematic boundary observations")
  }
  
  tt = t.test(Yi)
  if(plotit){
    plot(Yi, type="n",ylab="black=actual;green=transformed;blue=conf", xlab=paste0("p=",round(tt$p.value,5)), ylim=c(min(c(af.vec,Yi)), max(c(af.vec,Yi))))
    lines(af.vec, lwd=1, lty=3)
    abline(h=0, col="lightgray")
    lines(Yi, col=rgb(0.3,0.5,0.1,0.9), lwd=2)
    abline(h=mean(Yi), col=rgb(0,0.7,0.2,0.9))
    rect(1, tt$estimate-tt$conf.int[1],length(af.vec), tt$estimate+tt$conf.int[1],
         col=rgb(0,0.1,0.9,0.2), border=NA)
  }
  if(returntest) return(tt)
  if(!returntest) return(tt$p.value)
}

doexampleplot = function(wh){
  set.seed(3);  curve=(1/(1+exp(-18*(seq(0.2,0.8,length.out = 10)-0.5) ) ))+rnorm(10,0,0.01);curve=ifelse(curve>1,0.99,abs(curve));a1=rnorm(8,0.02,0.01);a2=rnorm(8,0.98,0.01);set.seed(10);curve=(1/(1+exp(-18*(seq(0.2,0.8,length.out = 10)-0.5) ) ))+rnorm(10,0,0.01);curve=ifelse(curve>1,0.99,abs(curve)); exmp=list(
          
          # the sharp rise, depends on the corpus window
          #1/(1+exp(-20*(seq(0.01,0.95,length.out = 12)-0.9)))+0.1, 
          c(a1, (1/(1+exp(-15*(seq(0.1,0.9,length.out = 11)-0.5) ) ))[3:6] ),
          c( (1/(1+exp(-15*(seq(0.1,0.9,length.out = 11)-0.5) ) ))[6:9] , a2 ),
          #c(x3, (1/(1+exp(-15*(seq(0.1,0.9,length.out = 11)-0.5) ) ))[3:9] , runif(8,0.98,0.999)  ),
          
          # bump and long window
          c(rep(0,1), (0.8/(1+exp(-15*(seq(0.1,0.9,length.out = 6)-0.5) ) )),0.8-(0.8/(1+exp(-15*(seq(0.1,0.9,length.out = 6)-0.5) ) )), rep(0,2) ),
          #c(runif(20,0.001,0.01), (0.8/(1+exp(-15*(seq(0.1,0.9,length.out = 6)-0.5) ) )),0.8-(0.8/(1+exp(-15*(seq(0.1,0.9,length.out = 6)-0.5) ) )), runif(20,0.001,0.01) ),
          {set.seed(100); c( rep(0,7), runif(4,0.001,0.01), 1/(1+exp(-21*(seq(0.1,0.9,length.out = 9)-0.5))) ,runif(4,0.98,0.998), rep(1,5) )},
          
          # c, 7vs9
          1/(1+exp(-21*(seq(0.1,0.9,length.out = 7)-0.5))),  1/(1+exp(-21*(seq(0.1,0.9,length.out = 9)-0.5))),
          
          # d,  almost identical S-curves (with linear middle bits) get different p
          c(rep(0,3), NA, seq(0.36,0.9,length.out = 3), rep(1,2)  ),
          c(rep(0,3), 0.05, seq(0.36,0.9,length.out = 3), rep(1,2)  ), # shift 4 below
          
          # linear
          #seq(0.05,0.55,length.out=7), seq(0.25,0.75,length.out=7),
          
          # all these usually get p<0.05 for the longer one:
          # runif(13,0.001,0.01), runif(130,0.001,0.01),
          # rlnorm(13,log(0.0055), 0.5), rlnorm(130,log(0.0055), 0.5)
          #rnorm(10,0.001, 0.0005), rnorm(100,0.001, 0.0005),
          approx(curve,n=20)$y,
          NA
          ); exmp[[7]][4] = 0.2; set.seed(100);exmp[[10]] = rnorm(50, 0.005, 0.006) #rnorm(50, 0.003, 0.0035)


  #pdf(file = "/Users/pplsuser/Dropbox/phd/selection_replypaper/fitexamples.pdf", width = 9.2, height = 5)
  #library(nortest)
  library(vioplot) # uses dev v0.3
  par(mar=c(1.9, 0.2, 0.4, 0.2), cex.axis=0.7, oma=c(0,2.5,1.3,0))
  layout(matrix(1:length(exmp), nrow=2, ncol=length(exmp)/2, byrow = F), widths=rep(1/6,6)) # arrangement
  abc = c(
     "window matters", "", "missed selection events","", "2 points difference", "","sensitive near 0", "", "normality question", "")
  corners = paste(letters[c(1,1,2,2,3,3,4,4,5,5,6,6)], rep(1:2,6), sep=".")
  for(j in 1:(length(exmp))){
    #if(j==3) par(mar=c(3,2,0.5,0.2))
    plot(exmp[[j]], type="n", 
         xlim=c(0.3,length(exmp[[j]])+length(exmp[[j]])/50),  
         ylim=c(-0.08,1.5), 
         xlab="", ylab="",xaxt = "n",yaxt="n",tck = 0.03)
    abline(h=c(0,1), lty=1, lwd=1, col="lightgray")
    if(length(exmp[[j]])<25){ axis(1, 1:length(exmp[[j]]))} else { axis(1)}
    #axis(2,tck = 0.03, labels=NA)
    axis(4, labels=NA, tck=-0.03) # tck = 0.03,
    if(j<3) axis(2)
    
    if(j %in% wh){
    v=exmp[[j]]; v=ifelse(v <= 0, 0.001, ifelse(v >= 1, 0.999, v))
    t=1:length(v)
    Y = rep(0,(length(v))); Y[1]=NA
    for (i in c(2:length(v))) { # put increment value on the correct slot in Y to plot
      Y[i] = (v[i] - v[i - 1])/sqrt( 2*v[i-1]*(1 - v[i-1])*(t[i] - t[i-1]) )
    }
    swp=NA;fp=NA
    try({swp=shapiro.test(Y)$p.value})
    #swp=lillie.test(Y)$p.value
    try({ fp=FIT(exmp[[j]]) })
    pval=function(p){x= ifelse(p<0.001,"<0.001",paste0("=",p,collapse=""));return( bquote(italic(p)[FIT]~.(x)) )}
    sval=function(p){x= ifelse(p<0.001,"<0.001",paste0("=",p,collapse=""));return( bquote(italic(p)[SW]~.(x)) )}
    text(length(exmp[[j]]),c(1.48), pval(round(fp,3)), cex=1.4, adj=c(1,0.5))
    text(length(exmp[[j]]),c(1.36), sval(round(swp,3)), cex=1.4, adj=c(1,0.5))
    
    if(j%%2){mtext(side = 3, abc[j], cex=0.8, line=0.2)}
   
    #print(swp)
    #plot(Y, type="o", pch=20, ylim=c(-0.5,0.5), xlab="", ylab="",xaxt = "n", lwd=0.5, col="gray")
    #if(!j%%2 | j==11) {ys[[ifelse(j==11,12,j)]] = Y}
    
    #points(rep(0.85, length(Y)), Y, cex=2, pch="-", col="darkgray") # increment rug
    vioplot(Y[!is.na(Y)], rectCol = F, col = "gray94", border=NA,add = T,
            at = (par('usr')[1]+1)/2, drawRect = F,side="both", wex=length(v)/7, lwd=0.5)
    segments(x0=(par('usr')[1]+1)/2, x1=(par('usr')[1]+1)/2,y0=min(Y,na.rm=T),y1=max(Y,na.rm=T), col="gray",lend=2,lwd=0.4)
    vioplot(Y[!is.na(Y)], rectCol = F, col = NA, border="gray58",add = T,
            at = (par('usr')[1]+1)/2, drawRect = F,side="both", wex=length(v)/7, lwd=0.5)
    
    lines(exmp[[j]], type="o", pch=20, lwd=1)  # actual values
    lines(Y, type="b", pch="-",cex=0.9, font=2, lwd=1, lty=3, col=rgb(0.3,0.3,0.3,0.8),font=2) # increment values
    
    if(j==1) {points(12, exmp[[j]][12],col="red")}
    if(j==2) {points(1, exmp[[j]][1],col="red")}
    if(j==4){ points(12, exmp[[j]][12],col="red");points(20, exmp[[j]][20],col="red")}
    if(j==6) {points(1, exmp[[j]][1],col="red"); points(9, exmp[[j]][9],col="red")}
    if(j %in% 7:8) {points(4, exmp[[j]][4],col="red")}
  }
    
    text(par('usr')[1]+0.1, 1.5, corners[[j]], cex=1.4, adj=c(0,0.5), font=2)
  }
#dev.off()
}


doslideplot = function(){
  #pdf(file = "/Users/pplsuser/Dropbox/phd/selection_replypaper/fitmaps1.pdf", width = 9.2, height = 5)
  mr=c(3, 3.5, 2,1)
  par(cex.axis=0.7, mar=mr, mfrow=c(2,2))
  layout(rbind(
    matrix(c(1,1,1, 2,3,4 ),  3, 2, byrow = F),
    #matrix(c(5,5), 1,2),
    matrix(c(1,1,1, 2,3,4 )+4,  3, 2, byrow = F)), 
    widths=c(7,3), heights=c(rep(1,3), rep(1,3) ))
  slideplot(fitm1)
  mtext(expression("Mean FIT"~italic(p)*"-values given 3 example selection strengths"~italic(s)), side = 3, outer=F, line=0.5, adj=0)
  text(1,0.3, "a", font = 2, cex=1.2, adj=c(1,1))
  #
  par(mar=c(0, 0.5,  2, 3)); wfexamples(ss=0.1, start=500, p=17)
  par(mar=c(1, 0.5,  1, 3)); wfexamples(ss=0.02, start=500, p=4)
  par(mar=c(2, 0.5, 0, 3));  wfexamples(ss=0.01, start=500, p=1)
  mtext("200 generations, starting at 50%",1, 1, cex=0.8)
  mtext("proportion of variant, 0...100%",4, -2, cex=0.8, outer = T, at = 0.75)
  #
  par(mar=c(0,0,0,0))
  #plot.new()
  par(mar=mr)
  slideplot(fitm2,leg=F)
  text(1,0.3, "b", font = 2, cex=1.2, adj=c(1,1))
  par(mar=c(1,1, 1, 3))
  par(mar=c(0, 0.5,  2, 3)); wfexamples(ss=0.1, start=50,p=17)
  par(mar=c(1, 0.5,  1, 3)); wfexamples(ss=0.02, start=50,p=4)
  par(mar=c(2, 0.5, 0, 3));  wfexamples(ss=0.01, start=50,p=1)
  mtext("200 generations, starting at 5%",1, 1, cex=0.8)
  mtext("proportion of variant, 0...100%",4, -2, cex=0.8, outer = T, at = 0.25)
  
  #dev.off()
}


dofitmap = function(f){
 # pdf(file = "/Users/pplsuser/Dropbox/phd/selection_replypaper/fitmaps2b.pdf", width = 9.2, height = 5)
  # layout(rbind(
  #   matrix(c(1,1,1,1,1, 2,2,2,2,2, 3,4,5,6,7 ),  5, 3, byrow = F),
  #   matrix(c(8,8,8), 1,3),
  #   matrix(c(1,1,1,1,1, 2,2,2,2,2, 3,4,5,6,7 )+8,5, 3, byrow = F)), widths=c(3,3,1), heights=c(rep(1,5),0.15, rep(1,5) ))
  par(cex.axis=0.7, mar=c(2.3, 3, 1.4, 3), mfrow=c(2,2))
  if(f==1) {fitmap(fitm1)} 
  if(f==2) {fitmap(fitm2)} 
  #par(mar=c(0.1,0.4,0.1,0.2))
  #wfexamples(start=500)
  #
  #plot.new() # empty row to give space
  #par(cex.axis=0.7, mar=c(3.5,3.6, 3.2,0))
  #par(mar=c(0.1,0.4,0.1,0.2))
  #wfexamples(start=100)
  
  #dev.off()
}

verbmap = function(vrbs=1:36){
  #pdf(file = "/Users/pplsuser/Dropbox/phd/selection_replypaper/verbmap.pdf", width = 9.2, height = 3.1)
  cols = RColorBrewer::brewer.pal(5, "RdYlBu")
  cols[2] = do.call(rgb, c(as.list(col2rgb(cols[2])-40),maxColorValue=255) )
  cols[3] = do.call(rgb, c(as.list(col2rgb(cols[3])-50),maxColorValue=255) )
  cols[4] = do.call(rgb, c(as.list(col2rgb(cols[4])+22),maxColorValue=255) )
    
  #cols = apply(col2rgb(cols), 2, function(x) rgb(x[1], x[2], x[3], 180, maxColorValue = 255))
  options(scipen = 999)
  # plot grid
  #layout(matrix(c(1,2), nrow=1), widths = c(4,2))
  par(cex.axis=0.9, mar=c(3, 2.5 ,0.5, 5), cex.axis=0.7)
  #plot(NA, ylim=c(0.001,1), xlim=c(1,36), log="y")
  plot(NA,  ylim=c(0.75,length(opts)+1), xlim=c(1.7,nrow(opts[[1]])+1), yaxt="n", ylab="", xlab="", xaxt="n")
  axis(1, 1:36, opts[[1]]$lemma, las=2, cex.axis=1, hadj=0.7)
  #axis(4, 1:36, opts[[1]]$lemma, las=1, cex.axis=0.7, hadj=0.3)
  axis(2, 1:(length(opts)+1), c(paste0("c=", c(0.5,0.75,1,1.25,1.5,2)), "", c("1y","5y","10y","15y","20y","25y", "40y")), las=2, hadj=0.7)
  
  mtext("fixed-width bins",side = 2,at = 11, line=1.7, cex=0.8,las=3)
  mtext("variable-\nwidth\nbins",side = 2,at = -1, line=0, cex=0.8, las=3)
  mtext("n(bins)",side = 1,at = 38, line=0.3, cex=0.8,las=1)
  
  abline(v=1:36, col="lightgray", lty=1)
  abline(h=3, col="lightgray", lwd=5)
  
  for(o in 1:length(opts) ){
      #points(i, opts[[o]]$FIT.p[i])
      #cl = ifelse(opts[[o]]$FIT.p < 0.05, cols[1], cols[4])
      cl = cols[2:4][cut(opts[[o]]$FIT.p[vrbs], breaks=c(-1,0.05,0.2,1) )]
      pc= c(22,16)[cut(opts[[o]]$W.p[vrbs]    , breaks=c(-1,0.1,1) )]
      lw = c(3,1)[cut(opts[[o]]$W.p[vrbs]     , breaks=c(-1,0.1,1) )]
      cx = c(1.4, 1.7)[cut(opts[[o]]$W.p[vrbs], breaks=c(-1,0.1,1) )]
      cx = ifelse(opts[[o]]$W.p[vrbs]>=0.1 & opts[[o]]$FIT.p[vrbs]<0.05, 2.3, cx)
      points(vrbs, rep(o+ifelse(o>6,1,0), length(vrbs)), col= cl, pch=pc, cex=cx, bg="white", lwd=lw)
      text(par("usr")[2]-0.1, o+ifelse(o>6,1,0), round(mean(opts[[o]]$q),1) , cex=0.8, adj=c(1,0.5))
  }
  #rect(6.7,0,7.3,37, border=NA, col="white");text(7, 1:36, opts[[1]]$lemma, cex=0.6)
  
  par(xpd=TRUE)
  legend("topright", inset=c(-0.13,0),legend = c( 
                         expression(italic(p)[FIT]<0.05),
                         expression(italic(p)[FIT]<0.2),
                         expression(italic(p)[FIT]>=0.2),
                         "",
                         expression(italic(p)[SW]<0.1),
                         expression(italic(p)[SW]>=0.1)
                         ),
  pch = c(16,16,16, NA, 0,16),bg = "white", col = c(cols[2],cols[3], cols[4],NA, "darkgray", "darkgray" ),pt.lwd=2, pt.cex=1.2, cex=0.9, y.intersp=1.1, x.intersp=0.5, box.lwd = 0,box.col = "white",  bty="n")
  
  #dev.off()
}


```


```{r plotlys, eval=F}
# run only once offline, do not compile/eval=F

cols = RColorBrewer::brewer.pal(5, "RdYlBu")
  cols[2] = do.call(rgb, c(as.list(col2rgb(cols[2])-40),maxColorValue=255) )
  cols[3] = do.call(rgb, c(as.list(col2rgb(cols[3])-50),maxColorValue=255) )
  cols[4] = do.call(rgb, c(as.list(col2rgb(cols[4])+22),maxColorValue=255) )
  
doline = function(bintype,qm=1, l, min10=T){
  variant.data = data.to.use %>% filter(lemma == l)
  freq = nrow(variant.data)
  # Determine regular variant
  variants = as.vector(unique(variant.data$vvd))
  regular.variant = variants[sapply(variants, nchar) == max(sapply(variants, nchar))]
  irregular.variant = variants[sapply(variants, nchar) == min(sapply(variants, nchar))]
  
  variant.df = variant.data %>% mutate(value = as.integer(vvd == regular.variant))
  
  # Set number of bins  
  n = nrow(variant.df)
  q = ceiling(log(n)*qm)

  
  # Bin the data by quantiles
  bn=bin.by.quantile(variant.df, q, bintype)
  variant.write = adjust.absorption(bn,min10 = min10) 
  df = variant.write %>% mutate(lemma = rep( l , nrow(bn)))
  if(min10){
    f = FIT.test(df)
    if(bintype=="q" & qm==1) lab="variable-width, c=1 (Newberry et al.)"
    if(bintype=="q" & qm!=1) lab=paste0("var-width, c=",qm)
    if(is.numeric(bintype)) lab=paste0("fixed-width ", bintype, "y")
    lab=paste0(lab, "; FITp=",round(f[[1]], 2), " S-Wp=",round(f[[2]], 2) )
    cl = as.numeric(cut(f[[1]], breaks=c(-1,0.05,0.2,1) ))
    df = cbind(df,  rel=df$value/df$count, b=lab, cl=cl)
  } else {
    df = cbind(df,  rel=df$value/df$count, b="na",cl=4 )
  }
  return(df)
}

l="light"
frames = rbind(
  doline(1,l=l, min10 = F),
      doline(1, l=l),
      doline(5, l=l),
      doline(10, l=l),
      doline(15, l=l),
      doline(20, l=l),
      doline(25, l=l),
      doline(40, l=l),
   data.frame(year=1800, value=0, count=0, lemma="", rel=0.5,   b=" ", cl=NA),
      {doline(1,l=l, min10 = F) %>% mutate(b=gsub("na", "na ", b))},
      doline("q", 2, l=l),
      doline("q", 1.5, l=l),
      doline("q", 1.25, l=l),
      doline("q", 1, l=l),
      doline("q", 0.75, l=l),
      doline("q", 0.5, l=l)
      )
p2 = frames %>% plot_ly(x=~year, y=~rel, frame=~b, type = 'scatter', mode = 'lines+markers', marker=list(size=7, color="black"), line=list(color="white")) %>%
  layout(xaxis=list(range=c(1809,2009), title=F, linecolor= 'black', linewidth=1, zeroline=F, showgrid=T, tickfont=list(size=20),titlefont=list(size=20)),
         yaxis=list(range=c(-0.01,1.01), title="<-lit   lighted->",linecolor= 'black', linewidth=1, zeroline=F,tickfont=list(size=20),titlefont=list(size=18) ),
         showlegend=F) %>%
  animation_opts(transition=300,frame=15000,  easing = "quad-in-out",redraw = T) %>%
  animation_slider(font=list(color="white")) %>%
  animation_button(label=">") %>% animation_slider(
    currentvalue = list(font = list(color="black"))) %>% 
  config(displayModeBar = F)
for(i in seq_along(p2$x$frames)){
  p2$x$frames[[i]]$data[[1]]$line$color = 
    c(cols[2:4],"white") [frames[frames$b==p2$x$frames[[i]]$name,"cl"][1]]
} 
p1=p2

l="spell"
frames = rbind(
  doline(1,l=l, min10 = F),
      doline(1, l=l),
      doline(5, l=l),
      doline(10, l=l),
      doline(15, l=l),
      doline(20, l=l),
      doline(25, l=l),
      doline(40, l=l),
   data.frame(year=1800, value=0, count=0, lemma="", rel=0.5,   b=" ", cl=NA),
      {doline(1,l=l, min10 = F) %>% mutate(b=gsub("na", "na ", b))},
      doline("q", 2, l=l),
      doline("q", 1.5, l=l),
      doline("q", 1.25, l=l),
      doline("q", 1, l=l),
      doline("q", 0.75, l=l),
      doline("q", 0.5, l=l)
      )
p2 = frames %>% plot_ly(x=~year, y=~rel, frame=~b, type = 'scatter', mode = 'lines+markers', marker=list(size=7, color="black"), line=list(color="white")) %>%
  layout(xaxis=list(range=c(1809,2009), title=F, linecolor= 'black', linewidth=1, zeroline=F, showgrid=T, tickfont=list(size=20),titlefont=list(size=20)),
         yaxis=list(range=c(-0.01,1.01), title="<-spelt   spelled->",linecolor= 'black', linewidth=1, zeroline=F,tickfont=list(size=20),titlefont=list(size=18) ),
         showlegend=F) %>%
  animation_opts(transition=300,frame=1500,  easing = "quad-in-out",redraw = T) %>%
  animation_slider(font=list(color="white")) %>%
  animation_button(label=">") %>% animation_slider(
    currentvalue = list(font = list(color="black"))) %>% 
  config(displayModeBar = F)

for(i in seq_along(p2$x$frames)){
  p2$x$frames[[i]]$data[[1]]$line$color = 
    c(cols[2:4],"white") [frames[frames$b==p2$x$frames[[i]]$name,"cl"][1]]
} 


# wfexample
ss=round(c(0,exp(seq(log(0.001), log(5), length.out = 200-1))),5)
wfval = c(); wfsd = c()
for(s in ss){
  tmp=sapply(1:100, function(x)wfsim(s,start = 50))
  wfval = c(wfval, rowMeans(tmp ) )
  wfsd =  c(wfsd, apply(tmp,1,sd))
}
wfdat = data.frame(wfval, x=rep(1:200,200), s=as.factor(sapply(ss,rep,200)),sd=wfsd )
cols=viridis::viridis(200,direction = -1)
#droplevels(wfdat[1:2000,]) %>% 
wf=wfdat %>%
  plot_ly(x=~x, y=~wfval, frame=~s, type="scatter", mode="lines",line=list(color=cols[1],width=3), error_y=~list(array=sd, color=rgb(0.9,0.9,0.9), thickness=2)) %>%
   layout(title="Wright-Fisher simulations (averaged; area=sd)",
     xaxis=list(zeroline=F, showgrid=T, title="generations"),
         yaxis=list(range=c(-5,1000), zeroline=F, title="population"),
         showlegend=F) %>%
  animation_opts(transition=0,frame=100,  easing = "linear",redraw = F) %>%
  animation_button(label=">") %>% 
  animation_slider(font=list(color="white"),currentvalue = list(font = list(color="black"))) %>%  config(displayModeBar = F)
for(i in seq_along(wf$x$frames)){
  wf$x$frames[[i]]$data[[1]]$line$color = cols[i]
} 

wf0 = plot_ly(x=1:200, y=ss, type="scatter", mode="markers", marker=list(color=cols,size=10)) %>% 
  layout(title="parameter space of s", showlegend=F, yaxis=list(title="selection strength s")) %>% config(displayModeBar = F)


save("p1", "p2", "wf0", "wf", file="/Users/pplsuser/Dropbox/phd/selection_replypaper/cletalk/plotlys.RData")

```

# A bit of background

---

# A bit of background
--

- All natural languages change over time
--

- Many have suggested that language change, like other evolutionary processes, involves both directed selection as well as stochastic drift .small[(Sapir1921, Jespersen1922, Andersen1987, Mcmahon1994, Croft2000, Blythe2012)] 
- Number of ways in which selective biases may influence language change .small[(Kirby2008, Smith2013, Enfield2014, Croft2000, Haspelmath1999, Labov2011, Mcmahon1994, Zipf1949, Baxter2006, Daoust2017; +et-al.'s )]
--

- Signatures of selection should be inferable from the usage data .small[(Sindi2016, Reali2010, Bentley2008, Amato2018, Kander2017; +et-al.'s)]
---

background-image: url(papershot.png)
background-size: contain

---
# Newberry et al. 2017, Detecting evolutionary forces in language change

- _"...we quantify the strength of selection relative to stochastic drift in language evolution."_

--

- _"...time series derived from large corpora of annotated texts"_ 
   - English verb (ir)regularization; COHA
   - Frequency Increment Test (FIT)
   
--

- _"...this work provides a method for testing selective theories of language change against a null model and reveals an underappreciated role for stochasticity in language evolution."_

---

# The Frequency Increment Test (FIT)

- Feder et al. 2014 .small[(from a family of tests of selection, cf. refs in paper)]
- Series of relative variant frequencies $v_i \in (0,1)$ at time $t_i$ 
- Transformed into frequency increments 
- $Y_i = (v_i-v_{i-1}) / \sqrt{ 2v_{i-1}(1-v_{i-1})(t_i-t_{i-1}) }$
--

- Rationale: under neutral evolution, the increments $v_i-v_{i-1}$ are normally distributed with a mean of 0, and variance ~ $v_{i-1}(1-v_{i-1})(t_i-t_{i-1})$ (inversely proportional to effective population size; when $0<<v_i<<1$; Gaussian approximation of the Wright-Fisher diffusion process)
--

- Test under the null hypothesis of drift ~ test that the increments are normally distributed with a mean of 0 (e.g.: one-sample $t$-test).

---

```{r fitexample, eval=T, fig.height=3, fig.width=5, dpi=200}
#knitr::knit_exit() # titleslide debug handbrake

ex = 1/(1+exp(-21*(seq(0.1,0.9,length.out = 9)-0.5))); ex[8]=ex[8]-0.1
library(vioplot) # uses dev v0.3
  par(mar=c(2, 3, 1, 1), cex.axis=0.8)
 j=1
    #if(j==3) par(mar=c(3,2,0.5,0.2))
    plot(ex, type="n", 
         xlim=c(0.3,length(ex)+length(ex)/50),  
         ylim=c(-1,1.5), 
         xlab="", ylab="",xaxt = "n",yaxt="n",tck = 0.03)
    abline(h=c(0,1), lty=1, lwd=1, col="gray")
    if(length(ex)<25){ axis(1, 1:length(ex))} else { axis(1)}
    #axis(2,tck = 0.03, labels=NA)
    axis(4, labels=NA, tck=-0.03) # tck = 0.03,
    axis(2)
    
    v=ex; v=ifelse(v <= 0, 0.001, ifelse(v >= 1, 0.999, v))
    t=1:length(v)
    Y = rep(0,(length(v))); Y[1]=NA
    for (i in c(2:length(v))) { # put increment value on the correct slot in Y to plot
      Y[i] = (v[i] - v[i - 1])/sqrt( 2*v[i-1]*(1 - v[i-1])*(t[i] - t[i-1]) )
    }
    swp=NA;fp=NA
    try({swp=shapiro.test(Y)$p.value})
    #swp=lillie.test(Y)$p.value
    try({ fp=FIT(ex) })
    pval=function(p){x= ifelse(p<0.001,"<0.001",paste0("=",p,collapse=""));return( bquote(italic(p)[FIT]~.(x)) )}
    sval=function(p){x= ifelse(p<0.001,"<0.001",paste0("=",p,collapse=""));return( bquote(italic(p)[SW]~.(x)) )}
    text(length(ex),c(1.48), pval(round(fp,3)), cex=1.4, adj=c(1,0.5))
    text(length(ex),c(1.2), sval(round(swp,3)), cex=1.4, adj=c(1,0.5))
  
    #points(rep(0.85, length(Y)), Y, cex=2, pch="-", col="darkgray") # increment rug
    vioplot(Y[!is.na(Y)], rectCol = F, col = "gray94", border=NA,add = T,
            at = (par('usr')[1]+1)/2, drawRect = F,side="both", wex=length(v)/7, lwd=0.5)
    segments(x0=(par('usr')[1]+1)/2, x1=(par('usr')[1]+1)/2,y0=min(Y,na.rm=T),y1=max(Y,na.rm=T), col="gray",lend=2,lwd=0.4)
    vioplot(Y[!is.na(Y)], rectCol = F, col = NA, border="gray58",add = T,
            at = (par('usr')[1]+1)/2, drawRect = F,side="both", wex=length(v)/7, lwd=0.5)
    
    lines(ex, type="o", pch=20, lwd=1)  # actual values
    lines(Y, type="b", pch="-",cex=1.5, font=2, lwd=1, lty=3, col=rgb(0.3,0.3,0.3,0.8),font=2) # increment values
  
  
    
    
```

---

# Problem: how to bin the data for time series

- Microbial experiments: samples that are taken at chosen intervals and resequenced
- Common approach in corpora usage: bin fixed length time segments
    - there is always a minimal time precision threshold (COHA: years)
    - but often not enough observations at fine precision 
    - so: decades, years, days, minutes
    - example: daily newspaper

--

- Newberry et al.: use variable width quantile binning, n(bins) = log(total frequency). Assures ~same number of occurrences per bin (but bins cover different lengths of time)

---
.pull-left[ 
```{r, fig.width=5.5, fig.height=5,dpi=100}
p1
```
]
.pull-right[
```{r, fig.width=5.5, fig.height=5,dpi=100}
p2   
```
]

---
class:inverse
# Replication of Newberry et al. 2017 (36 verbs)
---
# Replication of Newberry et al. 2017 (36 verbs)

```{r, eval=T, fig.height=4, fig.width=9, dpi=500}
verbmap()
```
---

# Replication of Newberry et al. 2017 (36 verbs)

```{r, eval=T, fig.height=4, fig.width=9, dpi=500}
verbmap(match( c("light", "smell", "sneak", "wake"), opts[[1]][,1]))
```

---

# Replication of Newberry et al. 2017 (36 verbs)

```{r, eval=T, fig.height=4, fig.width=9, dpi=500}
verbmap(c(6:7,9:14,26))
```

---

# Replication of Newberry et al. 2017 (36 verbs)

```{r, eval=T, fig.height=4, fig.width=9, dpi=500}
verbmap()
```
---

# Some thoughts

--

- In broad strokes, the generalization by Newberry et al. 2017 holds - selection is indeed detected in only ~3..7 verbs (depending on binning), and drift is quite prevalent (at $\alpha=0.05$).

--

- However, for most individual time series, the FIT result varies between binnings (except for ~3 almost unambiguous cases)

--

- So is it a good approach to study language change?<br>Depends on the goal.

--

- But still, what's the deal with the variation in the results...?


---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(1:10)
```
.small[What's going on?]
---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(1:2)
```
.small[(e.g. _spill, burn_)]
---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(3:4)
```
.small[(e.g. _knit_)]
---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(5:6)
```
.small[(differences between number of bins)]
---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(7:8)
```
---
```{r,eval=T, fig.height=4, fig.width=9, dpi=500}
doexampleplot(9:10)
```
.small[(e.g., _tell_)]
---
class:inverse
# Simulating change and applying binning<br>to determine the reasonable application range<br>of the FIT
---

# Simulating change and binning
--

- Run a large number of Wright-Fisher simulations with 200 different selection coefficients $s \in [0,5]$

--

- 200 generations, the "mutant" starting at 5% and 50% of the population of size 1000.

--

- For each $s$, bin the series in successively fewer number of bins <br>e.g. 200 (bin length 1) -> 100 (length 2) -> 66 (length 3) etc
    
--

- Repeat every combination 100x for good measure

---

.pull-left[ 
```{r, fig.width=5.5, fig.height=5,dpi=100}
wf0
```
]
.pull-right[
```{r, fig.width=5.5, fig.height=5,dpi=100}
wf  
```
]



---

```{r,eval=T, fig.height=4.5, fig.width=9, dpi=500}
doslideplot()
```

---
```{r,eval=T, fig.height=4.5, fig.width=9, dpi=500}
dofitmap(2)
```
---
```{r,eval=T, fig.height=4.5, fig.width=9, dpi=500}
dofitmap(1)
```

---

# Observations

- The FIT is insensitive to binning when selection is too weak ( $s<0.01$) to be detected; beyond about $s>0.02$ (depending on the start value) sensitivity to binning increases (false negatives)
--

- $0.01<s<0.02$ is relatively insensitive; but also where binning can instead decrease the FIT $p$-value (false positives)
--

- The normality assumption is systematically violated when $s$ approaches 0.1 (unless extreme binning is applied, which increases the false negative rate)

---

# Range of applicability of the FIT for linguistic data

- Conditions where the FIT is not reliably applicable:
    - partially completed changes, too short series
    - too few data points (sensitive to binning & absorption adjustment)
    - too long series (multiple events or processes)
    - too high selection (particularly with high binning)
    - small near-boundary fluctuations (false positives)
    - steep changes from boundary->non-boundary values
    - monotonically increasing series (normality assumption)
- Where it is:
    - weak selection, non-monotonic series away from 0/1, but window covering enough of (a single) change

---
class: inverse

# Conclusions
--

- What a time to be alive! .small[(data, methods, tools)]
--

- We evaluated the proposal of Newberry et al. 2017<br>Found that the results are dependent corpus binning, small sample effects, and the specifics of the FIT. 
- Testing vs generating hypotheses; degrees of freedom
--

- Fixing the issues would invite answers to numerous interesting questions

---
class: inverse

- Fixing these issues would invite answers to numerous interesting questions such as
--

   - Do different parts of grammar/lexicon experience stronger drift? 
--

   - What is the relationship of selection strength and niche in language change? .small[(cf. Laland2001, Altmann2011)] 
--

   - Can different types of selection (top-down, grassroots, momentum) be distinguished?  .small[(Amato2018, Stadler2016)]
--

   - What is the role of drift in creole evolution? .small[(Strimling2015)]
--

   - In semantic change? .small[(Hamilton2016)]
--
  
   - Are some languages changing more due to drift than others? Relation to community size? .small[(Reali2018, Atkinson2015)<br>(+et-al.'s)]

---
class: inverse
# Conclusions

- What a time to be alive!
- We evaluated the proposal of Newberry et al. 2017<br>Found that the results are dependent corpus binning, small sample effects, and the specifics of the FIT. 
- Testing vs generating hypotheses; degrees of freedom
- Fixing the issues would invite answers to numerous interesting questions
- Identifying the role of drift vs selection in language change is an important goal, but: care with applying such tests to linguistic data, to avoid biases due to specifics of the domain and the particular test.
- Slides, code & arXiv link at http://andreskarjus.github.io 

---
class: inverse
# Acknowledgements...

- Kenny Smith, Richard Blythe, Simon Kirby
- Mitchell Newberry
- Alison Feder
- .small[Support by the Kristjan Jaak program, funded by the Archimedes Foundation & Ministry of Education and Research of Estonia]




